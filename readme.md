data 张量类Tensor的实现和Tensor初始化方法
layer 算子的实现
parser Pnnx表达式的解析类
runtime 计算图结构，解析和运行时相关

自制深度学习推理框架：
1、张量：
实现张量的各种操作
2、计算图：
PNNX是旨在将pytorch模型导出为高效、简洁的计算图；
为什么要重新将pytorch模型再转换一次呢？我的理解是pytorch的框架是动态图，即可以灵活地对中间层进行操作，像普通代码那样灵活debug，
那么，在算子层面的计算就不会优化太多，比如不会使用算子融合等操作；但是自制框架可以去做这些；
（ONNX使用多个小算子去组合、等价一个复杂算子的设计，也是为了用尽可能少的算子去兼容更多的训练框架。
但是过于细碎的计算图会不仅不利于推理的优化。另外，拆分的层次过于细致，也会导致算法工程师难以将
导出的模型和原始模型进行结构上的相互对应。）
计算图包括以下几个部分：
一、Operator: 深度学习计算图中的计算节点。
二、Graph: 有多个Operator串联得到的有向无环图，规定了各个计算节点（Operator）执行的流程和顺序。
三、Layer: 计算节点中运算的具体执行者，Layer类先读取输入张量中的数据，然后对输入张量进行计算，
        得到的结果存放到计算节点的输出张量中，当然，不同的算子中Layer的计算过程会不一致。
四、Tensor: 用于存放多维数据的数据结构，方便数据在计算节点之间传递，同时该结构也封装矩阵乘、点积
        等与矩阵相关的基本操作。




框架支持哪些算子？如何扩展新的算子？
框架采用了模块化设计，扩展新算子只需实现算子逻辑、注册到工厂，并补充解析和测试，流程清晰，易于维护和扩展。


增加的工作：
conv+bn+relu层的算子融合
参考ggml的做法，提前预分配一定的内存

设计张量池（Tensor Pool）
实现一个全局或局部的张量池（如 TensorPool），用于管理和复用中间张量对象。
每次算子需要输出张量时，优先从池中获取已有的空闲张量，而不是新分配。
推理结束后，将不用的张量归还池中，等待下次复用。
静态图推理时预分配
在模型 build 阶段，分析每个算子的输入输出 shape，提前为所有中间节点分配好张量内存。
推理时直接复用这些预分配的张量，避免每次 forward 时 new/delete。
释放与生命周期管理
通过引用计数或拓扑排序，确定每个中间张量的最后一次使用点，及时归还池中。
可以结合智能指针和自定义 deleter 实现自动归还。


